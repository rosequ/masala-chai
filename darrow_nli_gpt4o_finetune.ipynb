{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cyera-gtm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hf://datasets/darrow-ai/LegalLensNLI-SharedTask/NLI.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>legal_act</th>\n",
       "      <th>label</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEFENDANT has reached a settlement in a class ...</td>\n",
       "      <td>Had to visit DEFENDANT a while back for some r...</td>\n",
       "      <td>privacy</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A class action lawsuit has been certified agai...</td>\n",
       "      <td>So, at 22, I was into this whole \"collect-and-...</td>\n",
       "      <td>consumer_protection</td>\n",
       "      <td>Entailed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEFENDANT, an auto parts supplier, has agreed ...</td>\n",
       "      <td>As an employee of the aforementioned auto part...</td>\n",
       "      <td>consumer_protection</td>\n",
       "      <td>Contradict</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEFENDANT has agreed to pay $400,000 to settle...</td>\n",
       "      <td>Hey, got a call from DEFENDANT a while back, s...</td>\n",
       "      <td>privacy</td>\n",
       "      <td>Contradict</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEFENDANT and other health benefit companies h...</td>\n",
       "      <td>Just checked my mail, got a letter from DEFEND...</td>\n",
       "      <td>privacy</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>DEFENDANT has reached a settlement in a breach...</td>\n",
       "      <td>Feeling a bit perplexed today. I've been a loy...</td>\n",
       "      <td>consumer_protection</td>\n",
       "      <td>Entailed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>DEFENDANT, a seafood restaurant operator in Ca...</td>\n",
       "      <td>Had a fantastic seafood dinner at this place l...</td>\n",
       "      <td>privacy</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Consumers who received promotional text messag...</td>\n",
       "      <td>Hardly ever use my phone for anything other th...</td>\n",
       "      <td>tcpa</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>DEFENDANT, a restaurant point-of-sale provider...</td>\n",
       "      <td>Upon my daily visits to the local diner, I fre...</td>\n",
       "      <td>privacy</td>\n",
       "      <td>Entailed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>DEFENDANT, an automotive, industrial, and comm...</td>\n",
       "      <td>Working at DEFENDANT, clocking in with a simpl...</td>\n",
       "      <td>privacy</td>\n",
       "      <td>Entailed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               premise  \\\n",
       "0    DEFENDANT has reached a settlement in a class ...   \n",
       "1    A class action lawsuit has been certified agai...   \n",
       "2    DEFENDANT, an auto parts supplier, has agreed ...   \n",
       "3    DEFENDANT has agreed to pay $400,000 to settle...   \n",
       "4    DEFENDANT and other health benefit companies h...   \n",
       "..                                                 ...   \n",
       "307  DEFENDANT has reached a settlement in a breach...   \n",
       "308  DEFENDANT, a seafood restaurant operator in Ca...   \n",
       "309  Consumers who received promotional text messag...   \n",
       "310  DEFENDANT, a restaurant point-of-sale provider...   \n",
       "311  DEFENDANT, an automotive, industrial, and comm...   \n",
       "\n",
       "                                            hypothesis            legal_act  \\\n",
       "0    Had to visit DEFENDANT a while back for some r...              privacy   \n",
       "1    So, at 22, I was into this whole \"collect-and-...  consumer_protection   \n",
       "2    As an employee of the aforementioned auto part...  consumer_protection   \n",
       "3    Hey, got a call from DEFENDANT a while back, s...              privacy   \n",
       "4    Just checked my mail, got a letter from DEFEND...              privacy   \n",
       "..                                                 ...                  ...   \n",
       "307  Feeling a bit perplexed today. I've been a loy...  consumer_protection   \n",
       "308  Had a fantastic seafood dinner at this place l...              privacy   \n",
       "309  Hardly ever use my phone for anything other th...                 tcpa   \n",
       "310  Upon my daily visits to the local diner, I fre...              privacy   \n",
       "311  Working at DEFENDANT, clocking in with a simpl...              privacy   \n",
       "\n",
       "          label  Unnamed: 4  \n",
       "0       Neutral         NaN  \n",
       "1      Entailed         NaN  \n",
       "2    Contradict         NaN  \n",
       "3    Contradict         NaN  \n",
       "4       Neutral         NaN  \n",
       "..          ...         ...  \n",
       "307    Entailed         NaN  \n",
       "308     Neutral         NaN  \n",
       "309     Neutral         NaN  \n",
       "310    Entailed         NaN  \n",
       "311    Entailed         NaN  \n",
       "\n",
       "[312 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "df = df[[\"premise\", \"hypothesis\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, eval_df = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Open a file in write mode\n",
    "with open('train_data.jsonl', 'w') as outfile:\n",
    "    for index, row in train_df.iterrows():\n",
    "        premise = row['premise']\n",
    "        hypothesis = row['hypothesis']\n",
    "        label = row['label']\n",
    "\n",
    "            \n",
    "        # Create the JSONL entry\n",
    "        jsonl_entry = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that given a pair of premise and hypothesis, you will predict the natural language inference between them: neutral, contradition, entailment\"},\n",
    "                {\"role\": \"user\", \"content\":  f\"premise: {premise}\\nhypothesis:{hypothesis}\"},\n",
    "                {\"role\": \"assistant\", \"content\": label}\n",
    "                ]\n",
    "        }\n",
    "        \n",
    "        # Write the JSONL entry to the file\n",
    "        json.dump(jsonl_entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file in write mode\n",
    "with open('eval_data.jsonl', 'w') as outfile:\n",
    "    for index, row in train_df.iterrows():\n",
    "        premise = row['premise']\n",
    "        hypothesis = row['hypothesis']\n",
    "        label = row['label']\n",
    "\n",
    "            \n",
    "        # Create the JSONL entry\n",
    "        jsonl_entry = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that given a pair of premise and hypothesis, you will predict the natural language inference between them: neutral, contradition, entailment\"},\n",
    "                {\"role\": \"user\", \"content\":  f\"premise: {premise}\\nhypothesis:{hypothesis}\"},\n",
    "                {\"role\": \"assistant\", \"content\": label}\n",
    "                ]\n",
    "        }\n",
    "        # Write the JSONL entry to the file\n",
    "        json.dump(jsonl_entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-46RRxDkbHkbsBxNNq9GmOtLi', bytes=324915, created_at=1724986965, filename='train_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "  file=open(\"train_data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-jsKvrU9sPNMDSz8YaDw2cuzQ', bytes=324915, created_at=1724986969, filename='eval_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "  file=open(\"eval_data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-qIHaGhJRB9bvWDWDxWPLJt6E', created_at=1724986980, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-Qxm4Gb8DM4gPh1hlxL8eCrsO', result_files=[], seed=19663938, status='validating_files', trained_tokens=None, training_file='file-46RRxDkbHkbsBxNNq9GmOtLi', validation_file='file-jsKvrU9sPNMDSz8YaDw2cuzQ', estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-46RRxDkbHkbsBxNNq9GmOtLi\", \n",
    "  model=\"gpt-4o-2024-08-06\",\n",
    "  validation_file=\"file-jsKvrU9sPNMDSz8YaDw2cuzQ\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-qIHaGhJRB9bvWDWDxWPLJt6E', created_at=1724986980, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-2024-08-06:georgian::A1mtDgxg', finished_at=1724989622, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-Qxm4Gb8DM4gPh1hlxL8eCrsO', result_files=['file-2SAYbt0iKfMP5N8xwzIuWhug'], seed=19663938, status='succeeded', trained_tokens=188877, training_file='file-46RRxDkbHkbsBxNNq9GmOtLi', validation_file='file-jsKvrU9sPNMDSz8YaDw2cuzQ', estimated_finish=None, integrations=[], user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "fine_tune_job = client.fine_tuning.jobs.retrieve(\"ftjob-qIHaGhJRB9bvWDWDxWPLJt6E\")\n",
    "print(fine_tune_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = pd.read_csv(\"/Users/royalsequiera/Projects/Darrow-LegalLens-NER/NLI_Task/testset_NLI_LegalLens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(premise, hypothesis) -> list[str]:\n",
    "    output = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:georgian::A1mtDgxg\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that given a pair of premise and hypothesis, you will predict the natural language inference between them: neutral, contradition, entailment\"},\n",
    "            {\"role\": \"user\", \"content\":  f\"premise: {premise}\\nhypothesis:{hypothesis}\"},\n",
    "        ]\n",
    "    ) \n",
    "    \n",
    "    output_str = output.choices[0].message.content\n",
    "    \n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[\"predictions\"] = df.apply(lambda x: model_inference(x[\"premise\"], x[\"hypothesis\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>DEFENDANT has agreed to a $5.25 million settle...</td>\n",
       "      <td>As a regular visitor to a certain company's fa...</td>\n",
       "      <td>Entailed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The DEFENDANT Text Message Class Action Settle...</td>\n",
       "      <td>Been receiving way too many texts from DEFENDA...</td>\n",
       "      <td>Entailed</td>\n",
       "      <td>Entailed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DEFENDANT has agreed to pay $7.5 million to se...</td>\n",
       "      <td>Stumbled upon my former employer in the news t...</td>\n",
       "      <td>Contradict</td>\n",
       "      <td>Entailed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>DEFENDANT, a hospital in Dixon, Illinois, has ...</td>\n",
       "      <td>So, there's this hospital in Dixon I went to a...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DEFENDANT, a company that provides ambulance a...</td>\n",
       "      <td>Recently started using the handprint clock-in ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               premise  \\\n",
       "228  DEFENDANT has agreed to a $5.25 million settle...   \n",
       "9    The DEFENDANT Text Message Class Action Settle...   \n",
       "57   DEFENDANT has agreed to pay $7.5 million to se...   \n",
       "60   DEFENDANT, a hospital in Dixon, Illinois, has ...   \n",
       "25   DEFENDANT, a company that provides ambulance a...   \n",
       "\n",
       "                                            hypothesis       label predictions  \n",
       "228  As a regular visitor to a certain company's fa...    Entailed         NaN  \n",
       "9    Been receiving way too many texts from DEFENDA...    Entailed    Entailed  \n",
       "57   Stumbled upon my former employer in the news t...  Contradict    Entailed  \n",
       "60   So, there's this hospital in Dixon I went to a...     Neutral     Neutral  \n",
       "25   Recently started using the handprint clock-in ...     Neutral     Neutral  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Contradict       0.67      0.12      0.20        34\n",
      "    Entailed       0.29      0.07      0.11        29\n",
      "     Neutral       0.40      0.19      0.26        31\n",
      "     unknown       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.13        94\n",
      "   macro avg       0.34      0.10      0.14        94\n",
      "weighted avg       0.46      0.13      0.19        94\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cyera-gtm/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cyera-gtm/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cyera-gtm/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "eval_df[\"predictions\"] = eval_df[\"predictions\"].fillna(\"unknown\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(eval_df[\"label\"], eval_df[\"predictions\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df[\"predictions\"] = inference_df.apply(lambda x: model_inference(x[\"premise\"], x[\"hypothesis\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Contradict\n",
       "1     Contradict\n",
       "2     Contradict\n",
       "3     Contradict\n",
       "4       Entailed\n",
       "         ...    \n",
       "79       Neutral\n",
       "80      Entailed\n",
       "81       Neutral\n",
       "82    Contradict\n",
       "83      Entailed\n",
       "Name: predictions, Length: 84, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df[\"predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3 = pd.read_csv(\"/Users/royalsequiera/Projects/Darrow-LegalLens-NER/NLI_Task/predictionsNLILens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11468879</td>\n",
       "      <td>DEFENDANT agreed to a settlement in a class ac...</td>\n",
       "      <td>I've been with DEFENDANT for a while now, and...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12135604</td>\n",
       "      <td>DEFENDANT has agreed to a $865,000 class actio...</td>\n",
       "      <td>Despite the data breach at DEFENDANT in Septe...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12332938</td>\n",
       "      <td>A settlement has been reached in a class actio...</td>\n",
       "      <td>I've used the point of sale systems in Illino...</td>\n",
       "      <td>Entailed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13798813</td>\n",
       "      <td>DEFENDANT has agreed to a $21.875M settlement ...</td>\n",
       "      <td>Never got any robocalls, DEFENDANT's settleme...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1576896</td>\n",
       "      <td>DEFENDANT has agreed to pay $2 million to sett...</td>\n",
       "      <td>I've been ordering my meals from DEFENDANT's ...</td>\n",
       "      <td>Entailed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        id                                            premise  \\\n",
       "0           0  11468879  DEFENDANT agreed to a settlement in a class ac...   \n",
       "1           1  12135604  DEFENDANT has agreed to a $865,000 class actio...   \n",
       "2           2  12332938  A settlement has been reached in a class actio...   \n",
       "3           3  13798813  DEFENDANT has agreed to a $21.875M settlement ...   \n",
       "4           4   1576896  DEFENDANT has agreed to pay $2 million to sett...   \n",
       "\n",
       "                                          hypothesis     label  \n",
       "0   I've been with DEFENDANT for a while now, and...   Neutral  \n",
       "1   Despite the data breach at DEFENDANT in Septe...   Neutral  \n",
       "2   I've used the point of sale systems in Illino...  Entailed  \n",
       "3   Never got any robocalls, DEFENDANT's settleme...   Neutral  \n",
       "4   I've been ordering my meals from DEFENDANT's ...  Entailed  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3.head()[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"NER_test_set_results_gpt4o_finetuned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/royalsequiera/Projects/Darrow-LegalLens-NER/NER_Task_Submission/predictions_NERLens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14243437</td>\n",
       "      <td>[\"a\",\"class\",\"action\",\"lawsuit\",\"has\",\"been\",\"...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18871551</td>\n",
       "      <td>[\"a\",\"media\",\"company\",\"recently\",\"came\",\"unde...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51514749</td>\n",
       "      <td>[\"a\",\"national\",\"bank\",\"was\",\"recently\",\"held\"...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99676183</td>\n",
       "      <td>[\"a\",\"recent\",\"case\",\"has\",\"come\",\"to\",\"light\"...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14188948</td>\n",
       "      <td>[\"a\",\"recent\",\"incident\",\"has\",\"come\",\"to\",\"li...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             tokens  \\\n",
       "0  14243437  [\"a\",\"class\",\"action\",\"lawsuit\",\"has\",\"been\",\"...   \n",
       "1  18871551  [\"a\",\"media\",\"company\",\"recently\",\"came\",\"unde...   \n",
       "2  51514749  [\"a\",\"national\",\"bank\",\"was\",\"recently\",\"held\"...   \n",
       "3  99676183  [\"a\",\"recent\",\"case\",\"has\",\"come\",\"to\",\"light\"...   \n",
       "4  14188948  [\"a\",\"recent\",\"incident\",\"has\",\"come\",\"to\",\"li...   \n",
       "\n",
       "                                      predicted_tags  \n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "4  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def format_token_tags_from_df(df):\n",
    "    formatted_data = []\n",
    "\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        # Safely evaluate strings that look like lists\n",
    "        tokens = row['tokens']\n",
    "        predicted_tags = row['predicted_tags']\n",
    "        \n",
    "        if isinstance(tokens, str):\n",
    "            tokens = ast.literal_eval(tokens)\n",
    "        if isinstance(predicted_tags, str):\n",
    "            predicted_tags = ast.literal_eval(predicted_tags)\n",
    "        \n",
    "        token_tag_pairs = [f\"{token}/{tag}\" for token, tag in zip(tokens, predicted_tags)]\n",
    "        formatted_string = ', '.join(token_tag_pairs)\n",
    "        formatted_data.append({'id': row['id'], 'formatted': formatted_string})\n",
    "\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 40410727,\n",
       "  'formatted': 'the/O, lead/O, plaintiff/O, alleges/O, that/O, the/O, app/O, has/O, been/O, issuing/B-VIOLATION, false/I-VIOLATION, and/I-VIOLATION, misleading/I-VIOLATION, financial/I-VIOLATION, statements,/I-VIOLATION, thereby/I-VIOLATION, artificially/I-VIOLATION, inflating/I-VIOLATION, the/I-VIOLATION, price/I-VIOLATION, of/I-VIOLATION, its/I-VIOLATION, securities/I-VIOLATION, ./O, this/O, unethical/O, behavior/O, was/O, orchestrated/O, by/O, the/O, apps/O, lead/O, developer/O, and/O, has/O, raised/O, serious/O, doubts/O, about/O, the/O, apps/O, reliability/O, ./O'},\n",
       " {'id': 61979338,\n",
       "  'formatted': 'a/O, restaurant/O, was/O, found/O, guilty/O, of/O, violating/O, the/O, fair/B-LAW, labor/I-LAW, standards/I-LAW, act/I-LAW, ./O, the/O, court/O, found/O, that/O, the/B-VIOLATED BY, restaurant/I-VIOLATED BY, management/I-VIOLATED BY, had/O, failed/O, to/O, comply/O, with/O, the/O, strict/O, notification/I-LAW, requirements/I-LAW, for/O, claiming/O, a/O, tip/O, credit,/O, including/O, notifying/O, employees/I-VIOLATION, of/O, the/O, cash/I-VIOLATION, wage,/I-VIOLATION, tip/I-VIOLATION, credit/I-VIOLATION, amount,/I-VIOLATION, limitations/I-VIOLATION, on/I-VIOLATION, tip/I-VIOLATION, credit,/I-VIOLATION, retention/I-VIOLATION, of/I-VIOLATION, tips,/I-VIOLATION, and/O, the/O, application/I-VIOLATION, of/I-VIOLATION, tip/I-VIOLATION, credit/I-VIOLATION, ./O, this/O, violation/O, was/O, committed/O, on/B-VIOLATED ON, the/I-VIOLATED ON, restaurants/I-VIOLATED ON, tipped/I-VIOLATED ON, employees/I-VIOLATED ON, ./O'}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_token_tags_from_df(df.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER File Check: NER prediction file format is correct.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_ner_format(predictions_file_path, test_file_path):\n",
    "    \"\"\"\n",
    "    Check the format of the NER prediction file.\n",
    "    The file should be in CSV format with columns: id, tokens, ner_tags\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(predictions_file_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        return False, f\"Error reading predictions CSV file: {e}\"\n",
    "    \n",
    "    try:\n",
    "        test_df = pd.read_csv(test_file_path)\n",
    "    except Exception as e:\n",
    "        return False, f\"Error reading test CSV file: {e}\"\n",
    "    \n",
    "    # Check expected columns\n",
    "    expected_columns = ['id', 'tokens', 'ner_tags']\n",
    "    pred_columns = list(df.columns)\n",
    "    for expected_col in expected_columns:\n",
    "        if expected_col not in pred_columns:\n",
    "            return False, f\"Incorrect columns. Expected: {expected_columns}, Found: {pred_columns}\"\n",
    "    \n",
    "    # Check number of rows\n",
    "    expected_ner_num_rows = len(test_df)\n",
    "    predictions_ner_num_rows = len(df)\n",
    "    if predictions_ner_num_rows != expected_ner_num_rows:\n",
    "        return False, f\"Incorrect number of predictions. Expected: {expected_ner_num_rows}, Found: {predictions_ner_num_rows}\"\n",
    "\n",
    "    return True, \"NER prediction file format is correct.\"\n",
    "\n",
    "def check_nli_format(predictions_file_path, test_file_path):\n",
    "    \"\"\"\n",
    "    Check the format of the NLI prediction file.\n",
    "    The file should be in CSV format with columns: Premise, hypothesis, label\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(predictions_file_path)\n",
    "    except Exception as e:\n",
    "        return False, f\"Error reading predictions CSV file: {e}\"\n",
    "    \n",
    "    try:\n",
    "        test_df = pd.read_csv(test_file_path)\n",
    "    except Exception as e:\n",
    "        return False, f\"Error reading test CSV file: {e}\"\n",
    "    \n",
    "    # Check expected columns\n",
    "    expected_columns = ['premise', 'hypothesis', 'label']\n",
    "    pred_columns = list(df.columns)\n",
    "    for expected_col in expected_columns:\n",
    "        if expected_col not in pred_columns:\n",
    "            return False, f\"Incorrect columns. Expected: {expected_columns}, Found: {pred_columns}\"\n",
    "    \n",
    "    # Check number of rows\n",
    "    expected_nli_num_rows = len(test_df)\n",
    "    predictions_nli_num_rows = len(df)\n",
    "    if predictions_nli_num_rows != expected_nli_num_rows:\n",
    "        return False, f\"Incorrect number of predictions. Expected: {expected_nli_num_rows}, Found: {predictions_nli_num_rows}\"\n",
    "    \n",
    "    return True, \"NLI prediction file format is correct.\"\n",
    "\n",
    "# Check NER prediction file\n",
    "ner_predictions_file_path = '/Users/royalsequiera/Projects/Darrow-LegalLens-NER/NER_Task_Submission/predictions_NERLens.csv' # replace with file path\n",
    "ner_test_file_path = '/Users/royalsequiera/Projects/Darrow-LegalLens-NER/NER_Task_Submission/test_NERLens.csv' # replace with file path\n",
    "is_valid, message = check_ner_format(ner_predictions_file_path, ner_test_file_path)\n",
    "print(f\"NER File Check: {message}\")\n",
    "\n",
    "# # Check NLI prediction file\n",
    "# nli_predictions_file_path = 'predictions_NLILens.csv' # replace with file path\n",
    "# nli_test_file_path = 'predictions_NLILens.csv' # replace with file path\n",
    "# is_valid, message = check_nli_format(nli_predictions_file_path, nli_test_file_path)\n",
    "# print(f\"NLI File Check: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the Excel file\n",
    "excel_file_path = '/Users/royalsequiera/Projects/Darrow-LegalLens-NER/NER_Task_Submission/NER_test_set.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = 'output_file.csv'\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
